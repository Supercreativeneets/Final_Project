{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f2_JC1G0ccPI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import split, mean\n",
    "from numpy import concatenate\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2OX2g-nxG6DK"
   },
   "outputs": [],
   "source": [
    "# Load the new file\n",
    "dataset = pd.read_csv('Final_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLLN9CW1evXb"
   },
   "source": [
    "The data starts from 01/03/2013 and ends on 28/02/2017.We will use the first three years of data for training predictive models and the final year for evaluating models. Hence, number of training days is 01/03/2013 - 29/02/2016, equals to 1096 days, i.e. 26304 hr. Number of test days is 01/03/2016 - 28/02/2017, 365 days, equals to 8760 hr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train/test sets\n",
    "\n",
    "def Split_dataset(data):\n",
    "    \n",
    "    # Split into train_data (1096 days X 24 hr) and val_data (219 days X 24 hr), test_data (146 days X 24 hr )\n",
    "    train, val, test = data[0:-8760], data[-8760:-3504], data[-3504:]\n",
    "\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train, val, test = Split_dataset(dataset.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26304, 22)\n",
      "(5256, 22)\n",
      "(3504, 22)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to convert the data in time series sequence such that it is a fixed size (24 hrs) moving window. It moves along one time step and predicts the subsequent 1hr.\n",
    "\n",
    "Input Output                                                                                                                   \n",
    "[h01, h02, h03, h04, . . . . , h21, h22, h23, h24], [h25]                                                                       \n",
    "[h02, h03, h04, h05, . . . . ,h22, h23, h24, h25], [h26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert series to supervised inputs and outputs\n",
    "\n",
    "def to_supervised(data, n_input=24, n_out=1):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised data\n",
    "train_X, train_y = to_supervised(train, n_input=24)\n",
    "val_X, val_y = to_supervised(val, n_input =24)\n",
    "test_X, test_y = to_supervised(test, n_input =24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26280, 24, 22)\n",
      "(26280, 1)\n",
      "(5232, 24, 22)\n",
      "(5232, 1)\n",
      "(3480, 24, 22)\n",
      "(3480, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(val_X.shape)\n",
    "print(val_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsY--04fWens"
   },
   "source": [
    "Now letâ€™s create a Baseline Metrics or else we may end up thinking our model works great when in fact it is doing worse than basic models. The simplest approach is to assume that predicted value is the last value of the sequence. This is called naive forecasting, and it is sometimes surprisingly difficult to outperform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42.],\n",
       "       [43.],\n",
       "       [47.],\n",
       "       ...,\n",
       "       [13.],\n",
       "       [16.],\n",
       "       [21.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "y_pred = test_X[ : ,-1:, 0]\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43.],\n",
       "       [47.],\n",
       "       [45.],\n",
       "       ...,\n",
       "       [16.],\n",
       "       [21.],\n",
       "       [19.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test RMSE: 23.620\n",
      "Baseline Test MAE: 12.443\n",
      "Baseline Test R2: 0.950\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(test_y, y_pred))\n",
    "print('Baseline Test RMSE: %.3f' % rmse)\n",
    "\n",
    "mae = mean_absolute_error(test_y,y_pred)\n",
    "print('Baseline Test MAE: %.3f' % mae)\n",
    "\n",
    "R2=r2_score(test_y,y_pred)\n",
    "print('Baseline Test R2: %.3f' % R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have baseline metrics\n",
    "\n",
    "Baseline Test RMSE: 23.620                                                                                                     \n",
    "Baseline Test MAE: 12.443                                                                                                       \n",
    "Baseline Test R2: 0.950                                                                                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
