{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f2_JC1G0ccPI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from numpy import split\n",
    "from numpy import concatenate\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras import callbacks\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2OX2g-nxG6DK"
   },
   "outputs": [],
   "source": [
    "# Load the new file\n",
    "dataset = pd.read_csv(\"Final_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLLN9CW1evXb"
   },
   "source": [
    "The data starts from 01/03/2013 and ends on 28/02/2017.We will use the first three years of data for training predictive models and the final year for evaluating models. Hence, number of training days is 01/03/2013 - 29/02/2016, equals to 1096 days, i.e. 26304 hr. Number of test days is 01/03/2016 - 28/02/2017, 365 days, equals to 8760 hr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6qntXEd5dsqs"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Split and scale the dataset into train/test sets\n",
    "\n",
    "def Split_dataset(data):\n",
    "    # Split into train_data (1096 days X 24 hr) and val_data (219 days X 24 hr), test_data (146 days X 24 hr )\n",
    "    train_data, val_data, test_data = data[0:-8760], data[-8760:-3504], data[-3504:]\n",
    "    \n",
    "    # scale the data using min max scaling on training data\n",
    "    train = scaler.fit_transform(train_data)\n",
    "    val = scaler.transform(val_data)\n",
    "    test = scaler.transform(test_data)\n",
    "    \n",
    "    # Restructure into windows of 24hrs\n",
    "    train = np.array(np.split(train, len(train) / 24))\n",
    "    val = np.array(np.split(val, len(val) / 24))\n",
    "    test = np.array(np.split(test, len(test) / 24))\n",
    "\n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NbRgvr4YKsni"
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train, val, test = Split_dataset(dataset.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUUN2DB1K4qJ",
    "outputId": "007c0c23-8a0d-4581-dd42-2d3c51e235d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 24, 22)\n",
      "(219, 24, 22)\n",
      "(146, 24, 22)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QogaT9opfEXX"
   },
   "source": [
    "We want to prepare the training data such that we iterate over the time steps and divide the data into overlapping windows; each iteration moves along 24 time steps (24hrs) and predicts the subsequent step 1hr.\n",
    "\n",
    "*   Input Output\n",
    "*   [h01, h02, h03, h04, . . . . , h21, h22, h23, h24], [h25]\n",
    "*   [h02, h03, h04, h05, . . . . ,h22, h23, h24, h25], [h26]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iNNBlWt8e2l7"
   },
   "outputs": [],
   "source": [
    "# Convert series to supervised inputs and outputs\n",
    "\n",
    "def to_supervised(data, n_input=24, n_out=1):\n",
    "    # flatten data\n",
    "    data = data.reshape((data.shape[0] * data.shape[1], data.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "def model_fit(train, val, config):\n",
    "\n",
    "    n_input, n_nodes, n_drop, n_epochs, n_batch = config\n",
    "\n",
    "    # Prepare training data\n",
    "    train_X, train_y = to_supervised(train, n_input=24)\n",
    "    val_X, val_y = to_supervised(val, n_input =24)\n",
    "\n",
    "    # Build the model\n",
    "    tf.random.set_seed(7)\n",
    "    np.random.seed(7)\n",
    "    n_input, n_features = train_X.shape[1], train_X.shape[2]\n",
    "    n_steps = train_X.shape[1]*train_X.shape[2]\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, activation='relu', input_dim = n_steps))\n",
    "    model.add(Dropout(n_drop))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss = 'mse' , optimizer= Adam(learning_rate = 0.001))\n",
    "\n",
    "    es_callback = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-4,\n",
    "                  patience=50, restore_best_weights=True)\n",
    "\n",
    "    # define inputs\n",
    "    train_X = train_X.reshape((train_X.shape[0], n_steps))\n",
    "    val_X = val_X.reshape((val_X.shape[0], n_steps))\n",
    "\n",
    "    # fit model\n",
    "    model.fit(train_X, train_y, epochs=n_epochs, batch_size=n_batch, verbose=1, validation_data = (val_X,val_y),callbacks=[es_callback])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, n_batch = config\n",
    "\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "\n",
    "    model = model_fit(train, val, config)\n",
    "\n",
    "    # shape input for model\n",
    "    test_X, test_y = to_supervised(test, n_input =24)\n",
    "    input_X = test_X.reshape((test_X.shape[0], test_X.shape[1]*test_X.shape[2]))\n",
    "\n",
    "    # make forecast\n",
    "    yhat = model.predict(input_X)\n",
    "\n",
    "    # actual observation\n",
    "    test_y = test_y.reshape(-1,1)\n",
    "\n",
    "    # invert scaling for actual\n",
    "    inv_test_y = concatenate((test_y, input_X[:, -21:]), axis=1)\n",
    "    inv_test_y = scaler.inverse_transform(inv_test_y)\n",
    "    inv_test_y= inv_test_y[:, 0]\n",
    "\n",
    "    # invert scaling for predictions\n",
    "    inv_yhat = concatenate((yhat, input_X[:, -21:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "    # estimate prediction error\n",
    "    rmse = sqrt(mean_squared_error(inv_test_y,inv_yhat))\n",
    "    mae = mean_absolute_error(inv_test_y, inv_yhat)\n",
    "    R2=r2_score(inv_test_y, inv_yhat)\n",
    "    \n",
    "    print('> Model[%s] %.3f %.3f %.3f' % (key, rmse, mae, R2))\n",
    "\n",
    "    return (key, rmse, mae, R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of configs to try\n",
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_input = [24]\n",
    "    n_nodes = [100, 200]\n",
    "    n_drop = [0.1, 0.2]\n",
    "    n_epochs = [200]\n",
    "    n_batch = [12, 24, 48]\n",
    "\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_input:\n",
    "      for j in n_nodes:\n",
    "        for k in n_drop:\n",
    "          for l in n_epochs:\n",
    "            for m in n_batch:\n",
    "              cfg = [i, j, k, l, m]\n",
    "              configs.append(cfg)\n",
    "      print('Total configs: %d' % len(configs))\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[24, 100, 0.1, 200, 12],\n",
       " [24, 100, 0.1, 200, 24],\n",
       " [24, 100, 0.1, 200, 48],\n",
       " [24, 100, 0.2, 200, 12],\n",
       " [24, 100, 0.2, 200, 24],\n",
       " [24, 100, 0.2, 200, 48],\n",
       " [24, 200, 0.1, 200, 12],\n",
       " [24, 200, 0.1, 200, 24],\n",
       " [24, 200, 0.1, 200, 48],\n",
       " [24, 200, 0.2, 200, 12],\n",
       " [24, 200, 0.2, 200, 24],\n",
       " [24, 200, 0.2, 200, 48]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_list = model_configs()\n",
    "cfg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search configs\n",
    "def grid_search(cfg_list):\n",
    "\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [model_predict(test, config) for config in cfg_list]\n",
    "\n",
    "    # sort configs by rmse, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 0.0031 - val_loss: 5.4521e-04\n",
      "Epoch 2/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 9.0168e-04 - val_loss: 7.9379e-04\n",
      "Epoch 3/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 8.3197e-04 - val_loss: 3.9890e-04\n",
      "Epoch 4/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 7.7420e-04 - val_loss: 5.0653e-04\n",
      "Epoch 5/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 7.3077e-04 - val_loss: 5.7666e-04\n",
      "Epoch 6/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 7.5588e-04 - val_loss: 4.6626e-04\n",
      "Epoch 7/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 7.3564e-04 - val_loss: 3.3402e-04\n",
      "Epoch 8/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 7.1546e-04 - val_loss: 4.8462e-04\n",
      "Epoch 9/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 7.1419e-04 - val_loss: 5.6578e-04\n",
      "Epoch 10/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.7622e-04 - val_loss: 4.5044e-04\n",
      "Epoch 11/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.6233e-04 - val_loss: 2.9493e-04\n",
      "Epoch 12/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.6266e-04 - val_loss: 3.4137e-04\n",
      "Epoch 13/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.6140e-04 - val_loss: 3.6390e-04\n",
      "Epoch 14/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.7085e-04 - val_loss: 4.0164e-04\n",
      "Epoch 15/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.4239e-04 - val_loss: 4.8409e-04\n",
      "Epoch 16/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.3663e-04 - val_loss: 2.8701e-04\n",
      "Epoch 17/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.4337e-04 - val_loss: 3.8255e-04\n",
      "Epoch 18/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.2194e-04 - val_loss: 3.4838e-04\n",
      "Epoch 19/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.3038e-04 - val_loss: 3.4976e-04\n",
      "Epoch 20/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.2424e-04 - val_loss: 3.3844e-04\n",
      "Epoch 21/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.3433e-04 - val_loss: 5.0101e-04\n",
      "Epoch 22/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.4261e-04 - val_loss: 2.8861e-04\n",
      "Epoch 23/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.1974e-04 - val_loss: 2.7691e-04\n",
      "Epoch 24/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.1200e-04 - val_loss: 2.6391e-04\n",
      "Epoch 25/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.2423e-04 - val_loss: 3.3121e-04\n",
      "Epoch 26/200\n",
      "2190/2190 [==============================] - 8s 4ms/step - loss: 6.2402e-04 - val_loss: 2.6874e-04\n",
      "Epoch 27/200\n",
      "2190/2190 [==============================] - 8s 4ms/step - loss: 6.5727e-04 - val_loss: 3.3284e-04\n",
      "Epoch 28/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.1608e-04 - val_loss: 2.7213e-04\n",
      "Epoch 29/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.4091e-04 - val_loss: 3.3544e-04\n",
      "Epoch 30/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.2822e-04 - val_loss: 2.9751e-04\n",
      "Epoch 31/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.3584e-04 - val_loss: 2.8511e-04\n",
      "Epoch 32/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.1603e-04 - val_loss: 2.7080e-04\n",
      "Epoch 33/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.0605e-04 - val_loss: 2.4330e-04\n",
      "Epoch 34/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.2462e-04 - val_loss: 2.9425e-04\n",
      "Epoch 35/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.2892e-04 - val_loss: 2.5564e-04\n",
      "Epoch 36/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.2144e-04 - val_loss: 2.6458e-04\n",
      "Epoch 37/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.1528e-04 - val_loss: 4.2245e-04\n",
      "Epoch 38/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.2170e-04 - val_loss: 3.0848e-04\n",
      "Epoch 39/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 5.9763e-04 - val_loss: 3.7740e-04\n",
      "Epoch 40/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.0525e-04 - val_loss: 2.8395e-04\n",
      "Epoch 41/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.2406e-04 - val_loss: 2.6011e-04\n",
      "Epoch 42/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.1392e-04 - val_loss: 4.6886e-04\n",
      "Epoch 43/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.1858e-04 - val_loss: 2.5954e-04\n",
      "Epoch 44/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 5.9954e-04 - val_loss: 2.9563e-04\n",
      "Epoch 45/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.3551e-04 - val_loss: 6.1503e-04\n",
      "Epoch 46/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.3443e-04 - val_loss: 2.8514e-04\n",
      "Epoch 47/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.1711e-04 - val_loss: 2.9974e-04\n",
      "Epoch 48/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.0599e-04 - val_loss: 2.6795e-04\n",
      "Epoch 49/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.1832e-04 - val_loss: 2.5122e-04\n",
      "Epoch 50/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.0440e-04 - val_loss: 2.4443e-04\n",
      "Epoch 51/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 5.9536e-04 - val_loss: 3.0291e-04\n",
      "Epoch 52/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 5.9856e-04 - val_loss: 2.4965e-04\n",
      "Epoch 53/200\n",
      "2190/2190 [==============================] - 7s 3ms/step - loss: 6.0224e-04 - val_loss: 2.7923e-04\n",
      "Epoch 54/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.1548e-04 - val_loss: 2.8141e-04\n",
      "Epoch 55/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.0725e-04 - val_loss: 3.5337e-04\n",
      "Epoch 56/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.1019e-04 - val_loss: 6.8442e-04\n",
      "Epoch 57/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.0916e-04 - val_loss: 3.3101e-04\n",
      "Epoch 58/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.1022e-04 - val_loss: 2.4163e-04\n",
      "Epoch 59/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1999e-04 - val_loss: 2.6704e-04\n",
      "Epoch 60/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 5.8769e-04 - val_loss: 3.1456e-04\n",
      "Epoch 61/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.3092e-04 - val_loss: 2.8238e-04\n",
      "> Model[[24, 100, 0.1, 200, 12]] 21.228 12.966 0.960\n",
      "Epoch 1/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 0.0057 - val_loss: 7.1622e-04\n",
      "Epoch 2/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 0.0010 - val_loss: 5.0313e-04\n",
      "Epoch 3/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 8.4913e-04 - val_loss: 4.3822e-04\n",
      "Epoch 4/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 7.8661e-04 - val_loss: 3.9751e-04\n",
      "Epoch 5/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 7.4248e-04 - val_loss: 8.0295e-04\n",
      "Epoch 6/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 7.5492e-04 - val_loss: 3.5171e-04\n",
      "Epoch 7/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 7.2295e-04 - val_loss: 3.5774e-04\n",
      "Epoch 8/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.7867e-04 - val_loss: 4.9553e-04\n",
      "Epoch 9/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.7414e-04 - val_loss: 3.3210e-04\n",
      "Epoch 10/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 6.4739e-04 - val_loss: 3.3324e-04\n",
      "Epoch 11/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.5119e-04 - val_loss: 2.9842e-04\n",
      "Epoch 12/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.3580e-04 - val_loss: 3.2205e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.1476e-04 - val_loss: 4.0663e-04\n",
      "Epoch 14/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.1203e-04 - val_loss: 3.5483e-04\n",
      "Epoch 15/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2243e-04 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2055e-04 - val_loss: 3.8746e-04\n",
      "Epoch 17/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.1440e-04 - val_loss: 3.3380e-04\n",
      "Epoch 18/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.9042e-04 - val_loss: 2.9247e-04\n",
      "Epoch 19/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.9595e-04 - val_loss: 3.1203e-04\n",
      "Epoch 20/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.0459e-04 - val_loss: 3.2709e-04\n",
      "Epoch 21/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.8706e-04 - val_loss: 2.9572e-04\n",
      "Epoch 22/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.8435e-04 - val_loss: 2.9407e-04\n",
      "Epoch 23/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.9042e-04 - val_loss: 2.7932e-04\n",
      "Epoch 24/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.7496e-04 - val_loss: 3.2397e-04\n",
      "Epoch 25/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.9383e-04 - val_loss: 2.8188e-04\n",
      "Epoch 26/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.8899e-04 - val_loss: 3.0476e-04\n",
      "Epoch 27/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.8263e-04 - val_loss: 2.6291e-04\n",
      "Epoch 28/200\n",
      "1095/1095 [==============================] - 4s 3ms/step - loss: 5.6926e-04 - val_loss: 2.9079e-04\n",
      "Epoch 29/200\n",
      "1095/1095 [==============================] - 4s 4ms/step - loss: 6.0750e-04 - val_loss: 2.6578e-04\n",
      "Epoch 30/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.7271e-04 - val_loss: 2.7929e-04\n",
      "Epoch 31/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 5.5922e-04 - val_loss: 2.5532e-04\n",
      "Epoch 32/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 5.6477e-04 - val_loss: 2.5389e-04\n",
      "Epoch 33/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.7304e-04 - val_loss: 2.9113e-04\n",
      "Epoch 34/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5582e-04 - val_loss: 2.8816e-04\n",
      "Epoch 35/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.6327e-04 - val_loss: 3.4200e-04\n",
      "Epoch 36/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5989e-04 - val_loss: 2.6862e-04\n",
      "Epoch 37/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5986e-04 - val_loss: 3.6326e-04\n",
      "Epoch 38/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.8078e-04 - val_loss: 3.0157e-04\n",
      "Epoch 39/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5836e-04 - val_loss: 2.8405e-04\n",
      "Epoch 40/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.9597e-04 - val_loss: 3.2004e-04\n",
      "Epoch 41/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.6471e-04 - val_loss: 2.4959e-04\n",
      "Epoch 42/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.6792e-04 - val_loss: 2.6685e-04\n",
      "Epoch 43/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.7070e-04 - val_loss: 4.1247e-04\n",
      "Epoch 44/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5866e-04 - val_loss: 2.4481e-04\n",
      "Epoch 45/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4132e-04 - val_loss: 2.6344e-04\n",
      "Epoch 46/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4460e-04 - val_loss: 3.0223e-04\n",
      "Epoch 47/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.7082e-04 - val_loss: 2.4690e-04\n",
      "Epoch 48/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.5243e-04 - val_loss: 2.8600e-04\n",
      "Epoch 49/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.7385e-04 - val_loss: 2.4999e-04\n",
      "Epoch 50/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5611e-04 - val_loss: 2.4589e-04\n",
      "Epoch 51/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5106e-04 - val_loss: 3.3118e-04\n",
      "Epoch 52/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5991e-04 - val_loss: 2.4646e-04\n",
      "Epoch 53/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4375e-04 - val_loss: 2.5127e-04\n",
      "Epoch 54/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5231e-04 - val_loss: 2.6095e-04\n",
      "Epoch 55/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 5.3256e-04 - val_loss: 3.4187e-04\n",
      "Epoch 56/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.3795e-04 - val_loss: 2.4904e-04\n",
      "Epoch 57/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5947e-04 - val_loss: 2.3682e-04\n",
      "Epoch 58/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.3761e-04 - val_loss: 2.5257e-04\n",
      "Epoch 59/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4053e-04 - val_loss: 2.7989e-04\n",
      "Epoch 60/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.3276e-04 - val_loss: 2.5171e-04\n",
      "Epoch 61/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.2967e-04 - val_loss: 2.8461e-04\n",
      "Epoch 62/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5935e-04 - val_loss: 2.4370e-04\n",
      "Epoch 63/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4548e-04 - val_loss: 2.9090e-04\n",
      "Epoch 64/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.3267e-04 - val_loss: 2.5960e-04\n",
      "Epoch 65/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4558e-04 - val_loss: 2.4644e-04\n",
      "Epoch 66/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4561e-04 - val_loss: 2.9979e-04\n",
      "Epoch 67/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.3437e-04 - val_loss: 2.4652e-04\n",
      "Epoch 68/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.2914e-04 - val_loss: 2.9400e-04\n",
      "> Model[[24, 100, 0.1, 200, 24]] 21.360 12.550 0.959\n",
      "Epoch 1/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0090 - val_loss: 0.0010\n",
      "Epoch 2/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0013 - val_loss: 6.8827e-04\n",
      "Epoch 3/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 9.9604e-04 - val_loss: 5.6014e-04\n",
      "Epoch 4/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 9.0241e-04 - val_loss: 5.0175e-04\n",
      "Epoch 5/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 8.0828e-04 - val_loss: 4.4225e-04\n",
      "Epoch 6/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.7812e-04 - val_loss: 5.2572e-04\n",
      "Epoch 7/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.7383e-04 - val_loss: 4.4427e-04\n",
      "Epoch 8/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.1832e-04 - val_loss: 4.5027e-04\n",
      "Epoch 9/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.0715e-04 - val_loss: 3.6076e-04\n",
      "Epoch 10/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.8018e-04 - val_loss: 3.4519e-04\n",
      "Epoch 11/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.5744e-04 - val_loss: 3.6334e-04\n",
      "Epoch 12/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.3536e-04 - val_loss: 3.2904e-04\n",
      "Epoch 13/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.3665e-04 - val_loss: 4.0749e-04\n",
      "Epoch 14/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9630e-04 - val_loss: 3.1323e-04\n",
      "Epoch 15/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.2418e-04 - val_loss: 4.0410e-04\n",
      "Epoch 16/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.2220e-04 - val_loss: 3.3378e-04\n",
      "Epoch 17/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.1366e-04 - val_loss: 3.0151e-04\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8638e-04 - val_loss: 3.1600e-04\n",
      "Epoch 19/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6889e-04 - val_loss: 3.4841e-04\n",
      "Epoch 20/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9365e-04 - val_loss: 3.1423e-04\n",
      "Epoch 21/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8341e-04 - val_loss: 3.3541e-04\n",
      "Epoch 22/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9361e-04 - val_loss: 2.8814e-04\n",
      "Epoch 23/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6736e-04 - val_loss: 2.6760e-04\n",
      "Epoch 24/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8615e-04 - val_loss: 2.7575e-04\n",
      "Epoch 25/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7096e-04 - val_loss: 4.3401e-04\n",
      "Epoch 26/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6267e-04 - val_loss: 2.6594e-04\n",
      "Epoch 27/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7178e-04 - val_loss: 3.4172e-04\n",
      "Epoch 28/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6205e-04 - val_loss: 2.6943e-04\n",
      "Epoch 29/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9045e-04 - val_loss: 2.7448e-04\n",
      "Epoch 30/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.5131e-04 - val_loss: 2.9995e-04\n",
      "Epoch 31/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.5390e-04 - val_loss: 3.1205e-04\n",
      "Epoch 32/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.3886e-04 - val_loss: 2.5941e-04\n",
      "Epoch 33/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.5287e-04 - val_loss: 2.5345e-04\n",
      "Epoch 34/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.6392e-04 - val_loss: 2.9790e-04\n",
      "Epoch 35/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4267e-04 - val_loss: 2.7388e-04\n",
      "Epoch 36/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 5.3739e-04 - val_loss: 2.6910e-04\n",
      "Epoch 37/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.5230e-04 - val_loss: 2.7638e-04\n",
      "Epoch 38/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 5.4402e-04 - val_loss: 2.6616e-04\n",
      "Epoch 39/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4388e-04 - val_loss: 2.9855e-04\n",
      "Epoch 40/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4733e-04 - val_loss: 4.2376e-04\n",
      "Epoch 41/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4267e-04 - val_loss: 2.5074e-04\n",
      "Epoch 42/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 5.5704e-04 - val_loss: 2.5186e-04\n",
      "Epoch 43/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.2769e-04 - val_loss: 2.7855e-04\n",
      "Epoch 44/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4104e-04 - val_loss: 2.6276e-04\n",
      "Epoch 45/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.5263e-04 - val_loss: 2.4517e-04\n",
      "Epoch 46/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4168e-04 - val_loss: 2.8290e-04\n",
      "Epoch 47/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.5080e-04 - val_loss: 2.6945e-04\n",
      "Epoch 48/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 5.2113e-04 - val_loss: 2.6264e-04\n",
      "Epoch 49/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.3629e-04 - val_loss: 2.8383e-04\n",
      "Epoch 50/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.1923e-04 - val_loss: 3.0173e-04\n",
      "Epoch 51/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.3694e-04 - val_loss: 2.6852e-04\n",
      "Epoch 52/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4178e-04 - val_loss: 2.8060e-04\n",
      "Epoch 53/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 5.2613e-04 - val_loss: 2.7860e-04\n",
      "Epoch 54/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.1828e-04 - val_loss: 2.4981e-04\n",
      "Epoch 55/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.3459e-04 - val_loss: 3.4022e-04\n",
      "Epoch 56/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.1642e-04 - val_loss: 2.8119e-04\n",
      "Epoch 57/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.3641e-04 - val_loss: 2.4542e-04\n",
      "Epoch 58/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4348e-04 - val_loss: 2.5876e-04\n",
      "Epoch 59/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 5.1870e-04 - val_loss: 2.6142e-04\n",
      "Epoch 60/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.4383e-04 - val_loss: 2.5731e-04\n",
      "Epoch 61/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.2732e-04 - val_loss: 2.6918e-04\n",
      "Epoch 62/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.5176e-04 - val_loss: 2.8069e-04\n",
      "> Model[[24, 100, 0.1, 200, 48]] 20.634 12.550 0.962\n",
      "Epoch 1/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 0.0038 - val_loss: 6.1429e-04\n",
      "Epoch 2/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 0.0011 - val_loss: 4.5709e-04\n",
      "Epoch 3/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 0.0011 - val_loss: 4.8836e-04\n",
      "Epoch 4/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 0.0010 - val_loss: 5.2064e-04\n",
      "Epoch 5/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 9.2167e-04 - val_loss: 6.6127e-04\n",
      "Epoch 6/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 9.4473e-04 - val_loss: 3.8247e-04\n",
      "Epoch 7/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 9.1256e-04 - val_loss: 3.7791e-04\n",
      "Epoch 8/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.9102e-04 - val_loss: 4.5230e-04\n",
      "Epoch 9/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.9872e-04 - val_loss: 6.3348e-04\n",
      "Epoch 10/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.5254e-04 - val_loss: 3.4169e-04\n",
      "Epoch 11/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.6746e-04 - val_loss: 3.5549e-04\n",
      "Epoch 12/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.9120e-04 - val_loss: 3.8315e-04\n",
      "Epoch 13/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.4208e-04 - val_loss: 5.8369e-04\n",
      "Epoch 14/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.4372e-04 - val_loss: 3.4450e-04\n",
      "Epoch 15/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.5308e-04 - val_loss: 6.3582e-04\n",
      "Epoch 16/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.3652e-04 - val_loss: 3.0707e-04\n",
      "Epoch 17/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2759e-04 - val_loss: 2.8938e-04\n",
      "Epoch 18/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.3043e-04 - val_loss: 3.3044e-04\n",
      "Epoch 19/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.3086e-04 - val_loss: 3.1404e-04\n",
      "Epoch 20/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2291e-04 - val_loss: 2.9168e-04\n",
      "Epoch 21/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.1494e-04 - val_loss: 4.4252e-04\n",
      "Epoch 22/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.5922e-04 - val_loss: 3.5783e-04\n",
      "Epoch 23/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1637e-04 - val_loss: 2.8771e-04\n",
      "Epoch 24/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 8.2524e-04 - val_loss: 2.8865e-04\n",
      "Epoch 25/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.1900e-04 - val_loss: 3.5459e-04\n",
      "Epoch 26/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.4049e-04 - val_loss: 3.4088e-04\n",
      "Epoch 27/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2719e-04 - val_loss: 2.9434e-04\n",
      "Epoch 28/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.1327e-04 - val_loss: 4.7492e-04\n",
      "Epoch 29/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.3507e-04 - val_loss: 4.8281e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2138e-04 - val_loss: 3.2215e-04\n",
      "Epoch 31/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.3235e-04 - val_loss: 2.8179e-04\n",
      "Epoch 32/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.7926e-04 - val_loss: 2.7672e-04\n",
      "Epoch 33/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.1990e-04 - val_loss: 2.7753e-04\n",
      "Epoch 34/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9419e-04 - val_loss: 2.8786e-04\n",
      "Epoch 35/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.0276e-04 - val_loss: 3.1967e-04\n",
      "Epoch 36/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.0874e-04 - val_loss: 3.8904e-04\n",
      "Epoch 37/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.0772e-04 - val_loss: 2.7135e-04\n",
      "Epoch 38/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9618e-04 - val_loss: 3.7472e-04\n",
      "Epoch 39/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.0586e-04 - val_loss: 2.5188e-04\n",
      "Epoch 40/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9249e-04 - val_loss: 3.0626e-04\n",
      "Epoch 41/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2245e-04 - val_loss: 2.6724e-04\n",
      "Epoch 42/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9735e-04 - val_loss: 4.4317e-04\n",
      "Epoch 43/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9204e-04 - val_loss: 2.6927e-04\n",
      "Epoch 44/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.7172e-04 - val_loss: 3.3791e-04\n",
      "Epoch 45/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2478e-04 - val_loss: 3.4197e-04\n",
      "Epoch 46/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2777e-04 - val_loss: 3.3184e-04\n",
      "Epoch 47/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.0502e-04 - val_loss: 2.4573e-04\n",
      "Epoch 48/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.8628e-04 - val_loss: 2.5448e-04\n",
      "Epoch 49/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.2499e-04 - val_loss: 2.5976e-04\n",
      "Epoch 50/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.0507e-04 - val_loss: 2.9209e-04\n",
      "Epoch 51/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9350e-04 - val_loss: 3.4431e-04\n",
      "Epoch 52/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.8002e-04 - val_loss: 2.7272e-04\n",
      "Epoch 53/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.8788e-04 - val_loss: 3.3240e-04\n",
      "Epoch 54/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9387e-04 - val_loss: 4.8651e-04\n",
      "Epoch 55/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.7268e-04 - val_loss: 4.4737e-04\n",
      "Epoch 56/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9443e-04 - val_loss: 3.2952e-04\n",
      "Epoch 57/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.9247e-04 - val_loss: 4.7959e-04\n",
      "Epoch 58/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.7435e-04 - val_loss: 3.2711e-04\n",
      "Epoch 59/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.1016e-04 - val_loss: 6.5990e-04\n",
      "Epoch 60/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.5649e-04 - val_loss: 2.7839e-04\n",
      "> Model[[24, 100, 0.2, 200, 12]] 23.374 14.857 0.951\n",
      "Epoch 1/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 0.0063 - val_loss: 7.5795e-04\n",
      "Epoch 2/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 5.4501e-04\n",
      "Epoch 3/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 4.9127e-04\n",
      "Epoch 4/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 9.6881e-04 - val_loss: 5.4993e-04\n",
      "Epoch 5/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 9.0331e-04 - val_loss: 9.6587e-04\n",
      "Epoch 6/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 9.0957e-04 - val_loss: 3.7723e-04\n",
      "Epoch 7/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 8.7672e-04 - val_loss: 3.7544e-04\n",
      "Epoch 8/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 8.5312e-04 - val_loss: 3.8034e-04\n",
      "Epoch 9/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 8.0516e-04 - val_loss: 4.0348e-04\n",
      "Epoch 10/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 8.0837e-04 - val_loss: 3.7540e-04\n",
      "Epoch 11/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 8.0471e-04 - val_loss: 3.4433e-04\n",
      "Epoch 12/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 8.0156e-04 - val_loss: 3.3396e-04\n",
      "Epoch 13/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5936e-04 - val_loss: 3.2741e-04\n",
      "Epoch 14/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.7759e-04 - val_loss: 3.5315e-04\n",
      "Epoch 15/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.6821e-04 - val_loss: 0.0012\n",
      "Epoch 16/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.8447e-04 - val_loss: 3.2972e-04\n",
      "Epoch 17/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 7.7296e-04 - val_loss: 2.8848e-04\n",
      "Epoch 18/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.6772e-04 - val_loss: 3.2753e-04\n",
      "Epoch 19/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.4692e-04 - val_loss: 2.9525e-04\n",
      "Epoch 20/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5459e-04 - val_loss: 3.1135e-04\n",
      "Epoch 21/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.4829e-04 - val_loss: 2.8333e-04\n",
      "Epoch 22/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.6115e-04 - val_loss: 3.1687e-04\n",
      "Epoch 23/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5645e-04 - val_loss: 3.4214e-04\n",
      "Epoch 24/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5077e-04 - val_loss: 3.0329e-04\n",
      "Epoch 25/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.6537e-04 - val_loss: 2.8844e-04\n",
      "Epoch 26/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5799e-04 - val_loss: 3.1336e-04\n",
      "Epoch 27/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5788e-04 - val_loss: 2.9557e-04\n",
      "Epoch 28/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.4801e-04 - val_loss: 2.8164e-04\n",
      "Epoch 29/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.6141e-04 - val_loss: 4.0995e-04\n",
      "Epoch 30/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2207e-04 - val_loss: 3.2508e-04\n",
      "Epoch 31/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2098e-04 - val_loss: 2.7406e-04\n",
      "Epoch 32/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.4575e-04 - val_loss: 2.8855e-04\n",
      "Epoch 33/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.3305e-04 - val_loss: 2.9179e-04\n",
      "Epoch 34/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0312e-04 - val_loss: 4.0642e-04\n",
      "Epoch 35/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.3458e-04 - val_loss: 3.0692e-04\n",
      "Epoch 36/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2530e-04 - val_loss: 3.0889e-04\n",
      "Epoch 37/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2809e-04 - val_loss: 5.6257e-04\n",
      "Epoch 38/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2149e-04 - val_loss: 2.8470e-04\n",
      "Epoch 39/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9795e-04 - val_loss: 2.9225e-04\n",
      "Epoch 40/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.3333e-04 - val_loss: 3.0879e-04\n",
      "Epoch 41/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.4921e-04 - val_loss: 2.5465e-04\n",
      "Epoch 42/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2310e-04 - val_loss: 2.5337e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2555e-04 - val_loss: 4.2716e-04\n",
      "Epoch 44/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.4053e-04 - val_loss: 2.6706e-04\n",
      "Epoch 45/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2214e-04 - val_loss: 2.8616e-04\n",
      "Epoch 46/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2237e-04 - val_loss: 3.6652e-04\n",
      "Epoch 47/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.3733e-04 - val_loss: 3.7662e-04\n",
      "Epoch 48/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9614e-04 - val_loss: 2.6117e-04\n",
      "Epoch 49/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2152e-04 - val_loss: 2.9113e-04\n",
      "Epoch 50/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2091e-04 - val_loss: 3.0603e-04\n",
      "Epoch 51/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0016e-04 - val_loss: 3.1058e-04\n",
      "Epoch 52/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9986e-04 - val_loss: 3.3991e-04\n",
      "Epoch 53/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2468e-04 - val_loss: 2.7466e-04\n",
      "Epoch 54/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0113e-04 - val_loss: 2.8009e-04\n",
      "Epoch 55/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.8844e-04 - val_loss: 3.6285e-04\n",
      "Epoch 56/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.7596e-04 - val_loss: 2.5815e-04\n",
      "Epoch 57/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.1580e-04 - val_loss: 2.5014e-04\n",
      "Epoch 58/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9667e-04 - val_loss: 2.6707e-04\n",
      "Epoch 59/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0622e-04 - val_loss: 4.9434e-04\n",
      "Epoch 60/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9489e-04 - val_loss: 2.5283e-04\n",
      "Epoch 61/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 6.9960e-04 - val_loss: 3.0928e-04\n",
      "Epoch 62/200\n",
      "1095/1095 [==============================] - 4s 4ms/step - loss: 7.3559e-04 - val_loss: 2.5103e-04\n",
      "Epoch 63/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.1533e-04 - val_loss: 2.4264e-04\n",
      "Epoch 64/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0288e-04 - val_loss: 3.3234e-04\n",
      "Epoch 65/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 7.0579e-04 - val_loss: 2.5480e-04\n",
      "Epoch 66/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9630e-04 - val_loss: 2.7593e-04\n",
      "Epoch 67/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.9548e-04 - val_loss: 2.7761e-04\n",
      "Epoch 68/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9731e-04 - val_loss: 3.1900e-04\n",
      "Epoch 69/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.8870e-04 - val_loss: 2.5885e-04\n",
      "Epoch 70/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.8364e-04 - val_loss: 2.7453e-04\n",
      "Epoch 71/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9403e-04 - val_loss: 2.4887e-04\n",
      "Epoch 72/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.3237e-04 - val_loss: 3.9087e-04\n",
      "Epoch 73/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0206e-04 - val_loss: 2.7552e-04\n",
      "Epoch 74/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9628e-04 - val_loss: 2.5654e-04\n",
      "Epoch 75/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2121e-04 - val_loss: 2.7700e-04\n",
      "Epoch 76/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.7878e-04 - val_loss: 2.5374e-04\n",
      "Epoch 77/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2537e-04 - val_loss: 2.7803e-04\n",
      "Epoch 78/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.6797e-04 - val_loss: 2.3819e-04\n",
      "Epoch 79/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.9923e-04 - val_loss: 2.4580e-04\n",
      "Epoch 80/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.8887e-04 - val_loss: 2.5580e-04\n",
      "Epoch 81/200\n",
      "1095/1095 [==============================] - 4s 4ms/step - loss: 6.9273e-04 - val_loss: 2.5029e-04\n",
      "> Model[[24, 100, 0.2, 200, 24]] 20.195 12.483 0.964\n",
      "Epoch 1/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 9.8791e-04\n",
      "Epoch 2/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 7.2603e-04\n",
      "Epoch 3/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 6.0318e-04\n",
      "Epoch 4/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 0.0011 - val_loss: 5.9407e-04\n",
      "Epoch 5/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 0.0010 - val_loss: 4.7677e-04\n",
      "Epoch 6/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 9.4220e-04 - val_loss: 4.9625e-04\n",
      "Epoch 7/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 9.1933e-04 - val_loss: 5.7037e-04\n",
      "Epoch 8/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 8.6546e-04 - val_loss: 4.4166e-04\n",
      "Epoch 9/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 8.3513e-04 - val_loss: 4.1819e-04\n",
      "Epoch 10/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 8.2444e-04 - val_loss: 3.7405e-04\n",
      "Epoch 11/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.9045e-04 - val_loss: 3.4780e-04\n",
      "Epoch 12/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 7.6043e-04 - val_loss: 3.3756e-04\n",
      "Epoch 13/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 8.0336e-04 - val_loss: 4.3501e-04\n",
      "Epoch 14/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.7174e-04 - val_loss: 3.2025e-04\n",
      "Epoch 15/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.3956e-04 - val_loss: 5.2440e-04\n",
      "Epoch 16/200\n",
      "548/548 [==============================] - 4s 8ms/step - loss: 7.4992e-04 - val_loss: 3.3183e-04\n",
      "Epoch 17/200\n",
      "548/548 [==============================] - 3s 6ms/step - loss: 7.7018e-04 - val_loss: 4.1104e-04\n",
      "Epoch 18/200\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 7.2973e-04 - val_loss: 3.1250e-04\n",
      "Epoch 19/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.2508e-04 - val_loss: 3.7711e-04\n",
      "Epoch 20/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.1460e-04 - val_loss: 3.0390e-04\n",
      "Epoch 21/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 7.2861e-04 - val_loss: 2.9085e-04\n",
      "Epoch 22/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.3481e-04 - val_loss: 2.9580e-04\n",
      "Epoch 23/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 7.0940e-04 - val_loss: 3.6183e-04\n",
      "Epoch 24/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.1133e-04 - val_loss: 2.8582e-04\n",
      "Epoch 25/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.2320e-04 - val_loss: 3.4894e-04\n",
      "Epoch 26/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 7.1382e-04 - val_loss: 3.4869e-04\n",
      "Epoch 27/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.1556e-04 - val_loss: 3.6162e-04\n",
      "Epoch 28/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 7.0230e-04 - val_loss: 3.2000e-04\n",
      "Epoch 29/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 7.2967e-04 - val_loss: 3.0086e-04\n",
      "Epoch 30/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 7.0517e-04 - val_loss: 3.5301e-04\n",
      "Epoch 31/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.9556e-04 - val_loss: 3.4978e-04\n",
      "Epoch 32/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.8116e-04 - val_loss: 2.8780e-04\n",
      "Epoch 33/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.9271e-04 - val_loss: 2.7902e-04\n",
      "Epoch 34/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.9015e-04 - val_loss: 5.1387e-04\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - 1s 2ms/step - loss: 6.8258e-04 - val_loss: 3.5080e-04\n",
      "Epoch 36/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.7150e-04 - val_loss: 4.5935e-04\n",
      "Epoch 37/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.8902e-04 - val_loss: 3.1715e-04\n",
      "Epoch 38/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.8812e-04 - val_loss: 2.8602e-04\n",
      "Epoch 39/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.9459e-04 - val_loss: 2.7704e-04\n",
      "Epoch 40/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.7224e-04 - val_loss: 2.8932e-04\n",
      "Epoch 41/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.7627e-04 - val_loss: 2.8149e-04\n",
      "Epoch 42/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.9681e-04 - val_loss: 2.9133e-04\n",
      "Epoch 43/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.7432e-04 - val_loss: 2.8947e-04\n",
      "Epoch 44/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6636e-04 - val_loss: 3.0681e-04\n",
      "Epoch 45/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.7921e-04 - val_loss: 2.7692e-04\n",
      "Epoch 46/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.8218e-04 - val_loss: 2.5682e-04\n",
      "Epoch 47/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.0793e-04 - val_loss: 2.5884e-04\n",
      "Epoch 48/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.4509e-04 - val_loss: 2.4688e-04\n",
      "Epoch 49/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.7016e-04 - val_loss: 2.9393e-04\n",
      "Epoch 50/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.7135e-04 - val_loss: 3.6767e-04\n",
      "Epoch 51/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5620e-04 - val_loss: 2.9684e-04\n",
      "Epoch 52/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.6901e-04 - val_loss: 2.8967e-04\n",
      "Epoch 53/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5008e-04 - val_loss: 2.5686e-04\n",
      "Epoch 54/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.4073e-04 - val_loss: 2.5205e-04\n",
      "Epoch 55/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6885e-04 - val_loss: 6.2678e-04\n",
      "Epoch 56/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5252e-04 - val_loss: 2.5271e-04\n",
      "Epoch 57/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.5476e-04 - val_loss: 2.5533e-04\n",
      "Epoch 58/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.7549e-04 - val_loss: 3.1115e-04\n",
      "Epoch 59/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5759e-04 - val_loss: 3.0677e-04\n",
      "Epoch 60/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.8305e-04 - val_loss: 2.4661e-04\n",
      "Epoch 61/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.4618e-04 - val_loss: 2.8432e-04\n",
      "Epoch 62/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.7386e-04 - val_loss: 2.7072e-04\n",
      "Epoch 63/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6249e-04 - val_loss: 2.5221e-04\n",
      "Epoch 64/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5455e-04 - val_loss: 2.7057e-04\n",
      "Epoch 65/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.6275e-04 - val_loss: 2.5020e-04\n",
      "Epoch 66/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5576e-04 - val_loss: 4.1364e-04\n",
      "Epoch 67/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5708e-04 - val_loss: 2.6927e-04\n",
      "Epoch 68/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6786e-04 - val_loss: 2.8508e-04\n",
      "Epoch 69/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5540e-04 - val_loss: 2.9931e-04\n",
      "Epoch 70/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6118e-04 - val_loss: 2.6931e-04\n",
      "Epoch 71/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.7916e-04 - val_loss: 2.3986e-04\n",
      "Epoch 72/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6735e-04 - val_loss: 2.7648e-04\n",
      "Epoch 73/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4733e-04 - val_loss: 2.4136e-04\n",
      "Epoch 74/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.3028e-04 - val_loss: 2.6732e-04\n",
      "Epoch 75/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.6404e-04 - val_loss: 2.5808e-04\n",
      "Epoch 76/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4040e-04 - val_loss: 2.4257e-04\n",
      "Epoch 77/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.8822e-04 - val_loss: 4.1808e-04\n",
      "Epoch 78/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.5743e-04 - val_loss: 3.1447e-04\n",
      "Epoch 79/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.4629e-04 - val_loss: 2.5546e-04\n",
      "Epoch 80/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4982e-04 - val_loss: 2.8744e-04\n",
      "Epoch 81/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.3547e-04 - val_loss: 3.0263e-04\n",
      "Epoch 82/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6303e-04 - val_loss: 3.4225e-04\n",
      "Epoch 83/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.3250e-04 - val_loss: 2.5334e-04\n",
      "Epoch 84/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4405e-04 - val_loss: 2.4461e-04\n",
      "Epoch 85/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5783e-04 - val_loss: 2.5805e-04\n",
      "Epoch 86/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4106e-04 - val_loss: 3.4439e-04\n",
      "Epoch 87/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.5834e-04 - val_loss: 2.4702e-04\n",
      "Epoch 88/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.2532e-04 - val_loss: 2.7891e-04\n",
      "Epoch 89/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.5580e-04 - val_loss: 2.6098e-04\n",
      "Epoch 90/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.5196e-04 - val_loss: 2.6258e-04\n",
      "Epoch 91/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4718e-04 - val_loss: 2.3884e-04\n",
      "Epoch 92/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4301e-04 - val_loss: 2.5029e-04\n",
      "Epoch 93/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4481e-04 - val_loss: 2.7904e-04\n",
      "Epoch 94/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.3572e-04 - val_loss: 2.4582e-04\n",
      "Epoch 95/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4870e-04 - val_loss: 2.6651e-04\n",
      "Epoch 96/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 6.4030e-04 - val_loss: 2.4523e-04\n",
      "> Model[[24, 100, 0.2, 200, 48]] 20.288 12.327 0.963\n",
      "Epoch 1/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 0.0027 - val_loss: 5.6392e-04\n",
      "Epoch 2/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.5757e-04 - val_loss: 5.0350e-04\n",
      "Epoch 3/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1338e-04 - val_loss: 4.5208e-04\n",
      "Epoch 4/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.5445e-04 - val_loss: 7.0205e-04\n",
      "Epoch 5/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.0424e-04 - val_loss: 3.6115e-04\n",
      "Epoch 6/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.1867e-04 - val_loss: 4.8564e-04\n",
      "Epoch 7/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.0862e-04 - val_loss: 4.1980e-04\n",
      "Epoch 8/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.5270e-04 - val_loss: 4.3775e-04\n",
      "Epoch 9/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.8201e-04 - val_loss: 5.3275e-04\n",
      "Epoch 10/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.5788e-04 - val_loss: 3.5397e-04\n",
      "Epoch 11/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.4338e-04 - val_loss: 4.6918e-04\n",
      "Epoch 12/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.8199e-04 - val_loss: 4.0316e-04\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1824e-04 - val_loss: 4.3133e-04\n",
      "Epoch 14/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2469e-04 - val_loss: 3.0164e-04\n",
      "Epoch 15/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.3605e-04 - val_loss: 4.6413e-04\n",
      "Epoch 16/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 6.2808e-04 - val_loss: 2.7863e-04\n",
      "Epoch 17/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0433e-04 - val_loss: 4.0384e-04\n",
      "Epoch 18/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1457e-04 - val_loss: 4.3677e-04\n",
      "Epoch 19/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2357e-04 - val_loss: 3.9572e-04\n",
      "Epoch 20/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2716e-04 - val_loss: 3.5167e-04\n",
      "Epoch 21/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1001e-04 - val_loss: 5.2771e-04\n",
      "Epoch 22/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1309e-04 - val_loss: 2.7284e-04\n",
      "Epoch 23/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.1182e-04 - val_loss: 3.5200e-04\n",
      "Epoch 24/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 6.1171e-04 - val_loss: 3.3251e-04\n",
      "Epoch 25/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2278e-04 - val_loss: 2.9204e-04\n",
      "Epoch 26/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1445e-04 - val_loss: 2.7477e-04\n",
      "Epoch 27/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2982e-04 - val_loss: 2.6603e-04\n",
      "Epoch 28/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0000e-04 - val_loss: 2.8270e-04\n",
      "Epoch 29/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2231e-04 - val_loss: 3.0135e-04\n",
      "Epoch 30/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0887e-04 - val_loss: 4.0035e-04\n",
      "Epoch 31/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 5.9483e-04 - val_loss: 2.9131e-04\n",
      "Epoch 32/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1806e-04 - val_loss: 2.9420e-04\n",
      "Epoch 33/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0831e-04 - val_loss: 2.4712e-04\n",
      "Epoch 34/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0673e-04 - val_loss: 2.6658e-04\n",
      "Epoch 35/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.3873e-04 - val_loss: 4.5387e-04\n",
      "Epoch 36/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.4111e-04 - val_loss: 2.6188e-04\n",
      "Epoch 37/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1205e-04 - val_loss: 3.5761e-04\n",
      "Epoch 38/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 5.7632e-04 - val_loss: 2.7682e-04\n",
      "Epoch 39/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 5.9129e-04 - val_loss: 2.8606e-04\n",
      "Epoch 40/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.3686e-04 - val_loss: 2.8105e-04\n",
      "Epoch 41/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2038e-04 - val_loss: 2.9020e-04\n",
      "Epoch 42/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2429e-04 - val_loss: 2.7044e-04\n",
      "Epoch 43/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2176e-04 - val_loss: 2.8778e-04\n",
      "Epoch 44/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1239e-04 - val_loss: 2.8283e-04\n",
      "Epoch 45/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.4095e-04 - val_loss: 2.6320e-04\n",
      "Epoch 46/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1476e-04 - val_loss: 4.7875e-04\n",
      "Epoch 47/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0602e-04 - val_loss: 4.8962e-04\n",
      "Epoch 48/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2627e-04 - val_loss: 2.8579e-04\n",
      "Epoch 49/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2001e-04 - val_loss: 2.5292e-04\n",
      "Epoch 50/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2632e-04 - val_loss: 2.7399e-04\n",
      "Epoch 51/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1395e-04 - val_loss: 2.6747e-04\n",
      "Epoch 52/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1999e-04 - val_loss: 2.4272e-04\n",
      "Epoch 53/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1665e-04 - val_loss: 2.6637e-04\n",
      "Epoch 54/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0175e-04 - val_loss: 2.8226e-04\n",
      "Epoch 55/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1090e-04 - val_loss: 3.3383e-04\n",
      "Epoch 56/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.0447e-04 - val_loss: 4.4020e-04\n",
      "Epoch 57/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.4017e-04 - val_loss: 4.3197e-04\n",
      "Epoch 58/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.2439e-04 - val_loss: 2.9110e-04\n",
      "Epoch 59/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.6571e-04 - val_loss: 3.5097e-04\n",
      "Epoch 60/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.3103e-04 - val_loss: 3.0697e-04\n",
      "Epoch 61/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1383e-04 - val_loss: 2.6418e-04\n",
      "Epoch 62/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.4229e-04 - val_loss: 3.3603e-04\n",
      "Epoch 63/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.1770e-04 - val_loss: 2.8681e-04\n",
      "Epoch 64/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 6.3535e-04 - val_loss: 2.8436e-04\n",
      "> Model[[24, 200, 0.1, 200, 12]] 21.386 12.972 0.959\n",
      "Epoch 1/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 0.0044 - val_loss: 6.6909e-04\n",
      "Epoch 2/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 9.0654e-04 - val_loss: 5.4301e-04\n",
      "Epoch 3/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.4572e-04 - val_loss: 6.2010e-04\n",
      "Epoch 4/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.1063e-04 - val_loss: 4.4298e-04\n",
      "Epoch 5/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.5656e-04 - val_loss: 3.6530e-04\n",
      "Epoch 6/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.6133e-04 - val_loss: 3.4549e-04\n",
      "Epoch 7/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.3640e-04 - val_loss: 3.5267e-04\n",
      "Epoch 8/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.0845e-04 - val_loss: 5.9192e-04\n",
      "Epoch 9/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.0874e-04 - val_loss: 3.4856e-04\n",
      "Epoch 10/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.0898e-04 - val_loss: 3.0925e-04\n",
      "Epoch 11/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.8730e-04 - val_loss: 3.8131e-04\n",
      "Epoch 12/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.9419e-04 - val_loss: 3.3141e-04\n",
      "Epoch 13/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.6841e-04 - val_loss: 3.9162e-04\n",
      "Epoch 14/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.5145e-04 - val_loss: 3.1638e-04\n",
      "Epoch 15/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.0026e-04 - val_loss: 9.7001e-04\n",
      "Epoch 16/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.7792e-04 - val_loss: 3.5683e-04\n",
      "Epoch 17/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.5249e-04 - val_loss: 3.3248e-04\n",
      "Epoch 18/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.5293e-04 - val_loss: 3.2999e-04\n",
      "Epoch 19/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.4967e-04 - val_loss: 4.8170e-04\n",
      "Epoch 20/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4507e-04 - val_loss: 2.8567e-04\n",
      "Epoch 21/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.5054e-04 - val_loss: 3.1206e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.5041e-04 - val_loss: 2.8263e-04\n",
      "Epoch 23/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.4026e-04 - val_loss: 4.0354e-04\n",
      "Epoch 24/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.3202e-04 - val_loss: 3.9751e-04\n",
      "Epoch 25/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.4335e-04 - val_loss: 2.6567e-04\n",
      "Epoch 26/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.2377e-04 - val_loss: 3.1364e-04\n",
      "Epoch 27/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.4938e-04 - val_loss: 3.3557e-04\n",
      "Epoch 28/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1194e-04 - val_loss: 2.8419e-04\n",
      "Epoch 29/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.3232e-04 - val_loss: 3.4844e-04\n",
      "Epoch 30/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.4616e-04 - val_loss: 3.4062e-04\n",
      "Epoch 31/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.1454e-04 - val_loss: 2.6511e-04\n",
      "Epoch 32/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.3725e-04 - val_loss: 2.9550e-04\n",
      "Epoch 33/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.3821e-04 - val_loss: 2.7661e-04\n",
      "Epoch 34/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1518e-04 - val_loss: 2.8076e-04\n",
      "Epoch 35/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.3175e-04 - val_loss: 2.8088e-04\n",
      "Epoch 36/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1848e-04 - val_loss: 3.1547e-04\n",
      "Epoch 37/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.0224e-04 - val_loss: 2.9110e-04\n",
      "Epoch 38/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1594e-04 - val_loss: 3.3243e-04\n",
      "Epoch 39/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.0751e-04 - val_loss: 2.9161e-04\n",
      "Epoch 40/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.4624e-04 - val_loss: 3.5946e-04\n",
      "Epoch 41/200\n",
      "1095/1095 [==============================] - 4s 4ms/step - loss: 5.1306e-04 - val_loss: 2.5808e-04\n",
      "Epoch 42/200\n",
      "1095/1095 [==============================] - 4s 3ms/step - loss: 5.1312e-04 - val_loss: 2.6210e-04\n",
      "Epoch 43/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1143e-04 - val_loss: 3.1194e-04\n",
      "Epoch 44/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.1122e-04 - val_loss: 2.5607e-04\n",
      "Epoch 45/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.0840e-04 - val_loss: 2.4082e-04\n",
      "Epoch 46/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1176e-04 - val_loss: 3.0307e-04\n",
      "Epoch 47/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1174e-04 - val_loss: 3.8518e-04\n",
      "Epoch 48/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.0473e-04 - val_loss: 2.5400e-04\n",
      "Epoch 49/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 5.0608e-04 - val_loss: 2.6799e-04\n",
      "Epoch 50/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 5.2345e-04 - val_loss: 2.6084e-04\n",
      "Epoch 51/200\n",
      "1095/1095 [==============================] - 6s 5ms/step - loss: 4.9729e-04 - val_loss: 2.8901e-04\n",
      "Epoch 52/200\n",
      "1095/1095 [==============================] - 4s 3ms/step - loss: 5.0940e-04 - val_loss: 2.7729e-04\n",
      "Epoch 53/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 4.9874e-04 - val_loss: 2.4697e-04\n",
      "Epoch 54/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 4.9793e-04 - val_loss: 2.9529e-04\n",
      "Epoch 55/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.0927e-04 - val_loss: 3.8977e-04\n",
      "Epoch 56/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 4.9429e-04 - val_loss: 2.4811e-04\n",
      "Epoch 57/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.2338e-04 - val_loss: 2.5142e-04\n",
      "Epoch 58/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.0800e-04 - val_loss: 2.5045e-04\n",
      "Epoch 59/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 5.1629e-04 - val_loss: 2.8301e-04\n",
      "Epoch 60/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 4.8590e-04 - val_loss: 2.6549e-04\n",
      "> Model[[24, 200, 0.1, 200, 24]] 20.776 12.928 0.961\n",
      "Epoch 1/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0091 - val_loss: 9.7081e-04\n",
      "Epoch 2/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0012 - val_loss: 6.2358e-04\n",
      "Epoch 3/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 9.0704e-04 - val_loss: 5.2380e-04\n",
      "Epoch 4/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 8.0853e-04 - val_loss: 4.9452e-04\n",
      "Epoch 5/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.2284e-04 - val_loss: 4.2372e-04\n",
      "Epoch 6/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.7544e-04 - val_loss: 4.5666e-04\n",
      "Epoch 7/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.6622e-04 - val_loss: 4.0233e-04\n",
      "Epoch 8/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.2689e-04 - val_loss: 3.6026e-04\n",
      "Epoch 9/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.0478e-04 - val_loss: 7.0200e-04\n",
      "Epoch 10/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.2475e-04 - val_loss: 3.3160e-04\n",
      "Epoch 11/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.9378e-04 - val_loss: 3.3356e-04\n",
      "Epoch 12/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6747e-04 - val_loss: 3.3899e-04\n",
      "Epoch 13/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6174e-04 - val_loss: 3.3402e-04\n",
      "Epoch 14/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7563e-04 - val_loss: 3.2043e-04\n",
      "Epoch 15/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.5422e-04 - val_loss: 3.9888e-04\n",
      "Epoch 16/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.5191e-04 - val_loss: 3.1933e-04\n",
      "Epoch 17/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.3692e-04 - val_loss: 3.1341e-04\n",
      "Epoch 18/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.3049e-04 - val_loss: 2.9515e-04\n",
      "Epoch 19/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.0472e-04 - val_loss: 3.1212e-04\n",
      "Epoch 20/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.2318e-04 - val_loss: 2.7341e-04\n",
      "Epoch 21/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9837e-04 - val_loss: 3.0498e-04\n",
      "Epoch 22/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.1959e-04 - val_loss: 3.1261e-04\n",
      "Epoch 23/200\n",
      "548/548 [==============================] - 2s 4ms/step - loss: 5.0593e-04 - val_loss: 2.6213e-04\n",
      "Epoch 24/200\n",
      "548/548 [==============================] - 4s 7ms/step - loss: 4.8935e-04 - val_loss: 3.4058e-04\n",
      "Epoch 25/200\n",
      "548/548 [==============================] - 3s 6ms/step - loss: 5.1082e-04 - val_loss: 3.2663e-04\n",
      "Epoch 26/200\n",
      "548/548 [==============================] - 2s 4ms/step - loss: 5.2227e-04 - val_loss: 2.6694e-04\n",
      "Epoch 27/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8581e-04 - val_loss: 3.1790e-04\n",
      "Epoch 28/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9248e-04 - val_loss: 2.8457e-04\n",
      "Epoch 29/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9669e-04 - val_loss: 2.8438e-04\n",
      "Epoch 30/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8506e-04 - val_loss: 3.3778e-04\n",
      "Epoch 31/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7569e-04 - val_loss: 2.7362e-04\n",
      "Epoch 32/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7828e-04 - val_loss: 2.5371e-04\n",
      "Epoch 33/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9577e-04 - val_loss: 2.5476e-04\n",
      "Epoch 34/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9152e-04 - val_loss: 3.0479e-04\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8459e-04 - val_loss: 2.8734e-04\n",
      "Epoch 36/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7460e-04 - val_loss: 3.0192e-04\n",
      "Epoch 37/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6717e-04 - val_loss: 2.5896e-04\n",
      "Epoch 38/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6068e-04 - val_loss: 2.6134e-04\n",
      "Epoch 39/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6224e-04 - val_loss: 2.4159e-04\n",
      "Epoch 40/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8969e-04 - val_loss: 2.7911e-04\n",
      "Epoch 41/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8886e-04 - val_loss: 2.5220e-04\n",
      "Epoch 42/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7976e-04 - val_loss: 3.8972e-04\n",
      "Epoch 43/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6081e-04 - val_loss: 2.7590e-04\n",
      "Epoch 44/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5834e-04 - val_loss: 2.5292e-04\n",
      "Epoch 45/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7209e-04 - val_loss: 2.5151e-04\n",
      "Epoch 46/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4242e-04 - val_loss: 2.8788e-04\n",
      "Epoch 47/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6159e-04 - val_loss: 2.5690e-04\n",
      "Epoch 48/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5393e-04 - val_loss: 2.5892e-04\n",
      "Epoch 49/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6083e-04 - val_loss: 2.4849e-04\n",
      "Epoch 50/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6198e-04 - val_loss: 2.7550e-04\n",
      "Epoch 51/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5631e-04 - val_loss: 2.4796e-04\n",
      "Epoch 52/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7070e-04 - val_loss: 3.2202e-04\n",
      "Epoch 53/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6555e-04 - val_loss: 2.6945e-04\n",
      "Epoch 54/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.3519e-04 - val_loss: 2.8569e-04\n",
      "Epoch 55/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.4599e-04 - val_loss: 3.0931e-04\n",
      "Epoch 56/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4266e-04 - val_loss: 2.3858e-04\n",
      "Epoch 57/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.5219e-04 - val_loss: 2.3526e-04\n",
      "Epoch 58/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4819e-04 - val_loss: 2.4690e-04\n",
      "Epoch 59/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5397e-04 - val_loss: 2.5403e-04\n",
      "Epoch 60/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6114e-04 - val_loss: 2.6220e-04\n",
      "Epoch 61/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4216e-04 - val_loss: 2.4620e-04\n",
      "Epoch 62/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5727e-04 - val_loss: 3.5802e-04\n",
      "Epoch 63/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4271e-04 - val_loss: 2.3841e-04\n",
      "Epoch 64/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4202e-04 - val_loss: 2.5472e-04\n",
      "Epoch 65/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5004e-04 - val_loss: 2.8062e-04\n",
      "Epoch 66/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6241e-04 - val_loss: 2.4614e-04\n",
      "Epoch 67/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5048e-04 - val_loss: 2.4002e-04\n",
      "Epoch 68/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5612e-04 - val_loss: 2.7340e-04\n",
      "Epoch 69/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4474e-04 - val_loss: 3.4780e-04\n",
      "Epoch 70/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5993e-04 - val_loss: 2.5903e-04\n",
      "Epoch 71/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6678e-04 - val_loss: 2.4331e-04\n",
      "Epoch 72/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4995e-04 - val_loss: 2.9212e-04\n",
      "Epoch 73/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.3872e-04 - val_loss: 2.6077e-04\n",
      "Epoch 74/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.3430e-04 - val_loss: 2.5122e-04\n",
      "Epoch 75/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.3355e-04 - val_loss: 2.8557e-04\n",
      "Epoch 76/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.2955e-04 - val_loss: 2.5582e-04\n",
      "Epoch 77/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4494e-04 - val_loss: 2.3454e-04\n",
      "Epoch 78/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.4157e-04 - val_loss: 3.6606e-04\n",
      "Epoch 79/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4605e-04 - val_loss: 2.5541e-04\n",
      "Epoch 80/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4117e-04 - val_loss: 2.5679e-04\n",
      "Epoch 81/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.3746e-04 - val_loss: 2.3652e-04\n",
      "Epoch 82/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4427e-04 - val_loss: 2.3953e-04\n",
      "> Model[[24, 200, 0.1, 200, 48]] 19.869 11.745 0.965\n",
      "Epoch 1/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 0.0032 - val_loss: 6.2758e-04\n",
      "Epoch 2/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 0.0011 - val_loss: 7.7492e-04\n",
      "Epoch 3/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 9.9308e-04 - val_loss: 4.2287e-04\n",
      "Epoch 4/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 9.4436e-04 - val_loss: 8.2431e-04\n",
      "Epoch 5/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.9475e-04 - val_loss: 5.6036e-04\n",
      "Epoch 6/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.6634e-04 - val_loss: 4.0032e-04\n",
      "Epoch 7/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.7782e-04 - val_loss: 4.1093e-04\n",
      "Epoch 8/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.4661e-04 - val_loss: 7.1121e-04\n",
      "Epoch 9/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.5967e-04 - val_loss: 6.5351e-04\n",
      "Epoch 10/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 8.1289e-04 - val_loss: 3.3007e-04\n",
      "Epoch 11/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1922e-04 - val_loss: 6.0279e-04\n",
      "Epoch 12/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1933e-04 - val_loss: 4.5142e-04\n",
      "Epoch 13/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.0217e-04 - val_loss: 3.6652e-04\n",
      "Epoch 14/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1436e-04 - val_loss: 3.2142e-04\n",
      "Epoch 15/200\n",
      "2190/2190 [==============================] - 10s 4ms/step - loss: 8.4950e-04 - val_loss: 4.5718e-04\n",
      "Epoch 16/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.0576e-04 - val_loss: 3.5911e-04\n",
      "Epoch 17/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.0497e-04 - val_loss: 3.5867e-04\n",
      "Epoch 18/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.3329e-04 - val_loss: 3.1898e-04\n",
      "Epoch 19/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1776e-04 - val_loss: 3.1001e-04\n",
      "Epoch 20/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1772e-04 - val_loss: 4.0315e-04\n",
      "Epoch 21/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.8207e-04 - val_loss: 4.6028e-04\n",
      "Epoch 22/200\n",
      "2190/2190 [==============================] - 8s 4ms/step - loss: 8.0626e-04 - val_loss: 2.9640e-04\n",
      "Epoch 23/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.7433e-04 - val_loss: 3.2389e-04\n",
      "Epoch 24/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.7052e-04 - val_loss: 3.5735e-04\n",
      "Epoch 25/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.8850e-04 - val_loss: 3.3577e-04\n",
      "Epoch 26/200\n",
      "2190/2190 [==============================] - 6s 3ms/step - loss: 8.0384e-04 - val_loss: 3.8156e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.0399e-04 - val_loss: 2.7620e-04\n",
      "Epoch 28/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6734e-04 - val_loss: 4.3233e-04\n",
      "Epoch 29/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.0371e-04 - val_loss: 3.3515e-04\n",
      "Epoch 30/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.9952e-04 - val_loss: 5.5338e-04\n",
      "Epoch 31/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.9196e-04 - val_loss: 2.8558e-04\n",
      "Epoch 32/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.8711e-04 - val_loss: 4.0621e-04\n",
      "Epoch 33/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6843e-04 - val_loss: 2.6812e-04\n",
      "Epoch 34/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.7788e-04 - val_loss: 3.3764e-04\n",
      "Epoch 35/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6943e-04 - val_loss: 4.9885e-04\n",
      "Epoch 36/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.5145e-04 - val_loss: 2.6428e-04\n",
      "Epoch 37/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.8359e-04 - val_loss: 2.6059e-04\n",
      "Epoch 38/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.5683e-04 - val_loss: 2.8983e-04\n",
      "Epoch 39/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6190e-04 - val_loss: 3.9876e-04\n",
      "Epoch 40/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.7770e-04 - val_loss: 3.0086e-04\n",
      "Epoch 41/200\n",
      "2190/2190 [==============================] - 4s 2ms/step - loss: 7.4847e-04 - val_loss: 2.7522e-04\n",
      "Epoch 42/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6487e-04 - val_loss: 4.3329e-04\n",
      "Epoch 43/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.7500e-04 - val_loss: 3.1116e-04\n",
      "Epoch 44/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.7577e-04 - val_loss: 2.6235e-04\n",
      "Epoch 45/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6233e-04 - val_loss: 3.2874e-04\n",
      "Epoch 46/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.7183e-04 - val_loss: 2.6156e-04\n",
      "Epoch 47/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.5042e-04 - val_loss: 5.4187e-04\n",
      "Epoch 48/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6735e-04 - val_loss: 2.4869e-04\n",
      "Epoch 49/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.8410e-04 - val_loss: 2.6107e-04\n",
      "Epoch 50/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6140e-04 - val_loss: 2.4988e-04\n",
      "Epoch 51/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.8522e-04 - val_loss: 3.4774e-04\n",
      "Epoch 52/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.5330e-04 - val_loss: 2.5973e-04\n",
      "Epoch 53/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.0060e-04 - val_loss: 2.9780e-04\n",
      "Epoch 54/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6567e-04 - val_loss: 2.6351e-04\n",
      "Epoch 55/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.9230e-04 - val_loss: 3.6758e-04\n",
      "Epoch 56/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.5012e-04 - val_loss: 3.2427e-04\n",
      "Epoch 57/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.6647e-04 - val_loss: 3.2296e-04\n",
      "Epoch 58/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.5757e-04 - val_loss: 2.7830e-04\n",
      "Epoch 59/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.9438e-04 - val_loss: 3.1510e-04\n",
      "Epoch 60/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.1915e-04 - val_loss: 3.4869e-04\n",
      "Epoch 61/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.3758e-04 - val_loss: 2.7407e-04\n",
      "Epoch 62/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.7182e-04 - val_loss: 2.9258e-04\n",
      "Epoch 63/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 8.0200e-04 - val_loss: 2.5496e-04\n",
      "Epoch 64/200\n",
      "2190/2190 [==============================] - 5s 2ms/step - loss: 7.9567e-04 - val_loss: 2.8392e-04\n",
      "> Model[[24, 200, 0.2, 200, 12]] 21.472 12.849 0.959\n",
      "Epoch 1/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 0.0047 - val_loss: 7.1760e-04\n",
      "Epoch 2/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 5.8471e-04\n",
      "Epoch 3/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 8.6197e-04 - val_loss: 4.6262e-04\n",
      "Epoch 4/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 8.3262e-04 - val_loss: 4.2401e-04\n",
      "Epoch 5/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5538e-04 - val_loss: 4.2498e-04\n",
      "Epoch 6/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.5760e-04 - val_loss: 3.8932e-04\n",
      "Epoch 7/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.6970e-04 - val_loss: 3.7454e-04\n",
      "Epoch 8/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 7.0836e-04 - val_loss: 4.0649e-04\n",
      "Epoch 9/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.2556e-04 - val_loss: 4.4051e-04\n",
      "Epoch 10/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.9960e-04 - val_loss: 3.1807e-04\n",
      "Epoch 11/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0788e-04 - val_loss: 4.1904e-04\n",
      "Epoch 12/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 7.4684e-04 - val_loss: 3.9329e-04\n",
      "Epoch 13/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.8814e-04 - val_loss: 3.1084e-04\n",
      "Epoch 14/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.8224e-04 - val_loss: 4.1645e-04\n",
      "Epoch 15/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 7.0036e-04 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.8829e-04 - val_loss: 7.5163e-04\n",
      "Epoch 17/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.6446e-04 - val_loss: 3.2422e-04\n",
      "Epoch 18/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.7519e-04 - val_loss: 3.4270e-04\n",
      "Epoch 19/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.6733e-04 - val_loss: 5.9881e-04\n",
      "Epoch 20/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.5096e-04 - val_loss: 4.0744e-04\n",
      "Epoch 21/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.4356e-04 - val_loss: 2.7509e-04\n",
      "Epoch 22/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.6499e-04 - val_loss: 3.4244e-04\n",
      "Epoch 23/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.3501e-04 - val_loss: 3.1926e-04\n",
      "Epoch 24/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.3288e-04 - val_loss: 3.1342e-04\n",
      "Epoch 25/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.5880e-04 - val_loss: 2.6693e-04\n",
      "Epoch 26/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.3859e-04 - val_loss: 2.9889e-04\n",
      "Epoch 27/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.4209e-04 - val_loss: 2.8933e-04\n",
      "Epoch 28/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.3176e-04 - val_loss: 2.8423e-04\n",
      "Epoch 29/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.4456e-04 - val_loss: 3.0242e-04\n",
      "Epoch 30/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.4212e-04 - val_loss: 3.5755e-04\n",
      "Epoch 31/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.4031e-04 - val_loss: 2.5766e-04\n",
      "Epoch 32/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.3520e-04 - val_loss: 3.0688e-04\n",
      "Epoch 33/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.7684e-04 - val_loss: 3.9400e-04\n",
      "Epoch 34/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.1780e-04 - val_loss: 2.7217e-04\n",
      "Epoch 35/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.3491e-04 - val_loss: 3.4331e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.4059e-04 - val_loss: 3.7356e-04\n",
      "Epoch 37/200\n",
      "1095/1095 [==============================] - 4s 3ms/step - loss: 6.2323e-04 - val_loss: 2.6712e-04\n",
      "Epoch 38/200\n",
      "1095/1095 [==============================] - 4s 4ms/step - loss: 6.1477e-04 - val_loss: 3.0344e-04\n",
      "Epoch 39/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.4572e-04 - val_loss: 3.2990e-04\n",
      "Epoch 40/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.6533e-04 - val_loss: 3.0591e-04\n",
      "Epoch 41/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.1307e-04 - val_loss: 2.5831e-04\n",
      "Epoch 42/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 6.4804e-04 - val_loss: 3.5581e-04\n",
      "Epoch 43/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2535e-04 - val_loss: 3.1590e-04\n",
      "Epoch 44/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2926e-04 - val_loss: 2.8589e-04\n",
      "Epoch 45/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 6.5611e-04 - val_loss: 2.5130e-04\n",
      "Epoch 46/200\n",
      "1095/1095 [==============================] - 3s 3ms/step - loss: 6.3420e-04 - val_loss: 2.5896e-04\n",
      "Epoch 47/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.3078e-04 - val_loss: 3.4917e-04\n",
      "Epoch 48/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2314e-04 - val_loss: 2.4092e-04\n",
      "Epoch 49/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2055e-04 - val_loss: 2.5532e-04\n",
      "Epoch 50/200\n",
      "1095/1095 [==============================] - 2s 2ms/step - loss: 6.2607e-04 - val_loss: 2.7324e-04\n",
      "Epoch 51/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2933e-04 - val_loss: 3.2404e-04\n",
      "Epoch 52/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.2757e-04 - val_loss: 3.4137e-04\n",
      "Epoch 53/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.4980e-04 - val_loss: 2.4309e-04\n",
      "Epoch 54/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.1273e-04 - val_loss: 3.9748e-04\n",
      "Epoch 55/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.1971e-04 - val_loss: 2.8919e-04\n",
      "Epoch 56/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.0244e-04 - val_loss: 2.5881e-04\n",
      "Epoch 57/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.3230e-04 - val_loss: 2.4520e-04\n",
      "Epoch 58/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.3749e-04 - val_loss: 2.4391e-04\n",
      "Epoch 59/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.3346e-04 - val_loss: 3.0766e-04\n",
      "Epoch 60/200\n",
      "1095/1095 [==============================] - 3s 2ms/step - loss: 6.1823e-04 - val_loss: 2.4174e-04\n",
      "> Model[[24, 200, 0.2, 200, 24]] 20.317 11.863 0.963\n",
      "Epoch 1/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0101 - val_loss: 8.7910e-04\n",
      "Epoch 2/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0013 - val_loss: 6.5911e-04\n",
      "Epoch 3/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0010 - val_loss: 5.4231e-04\n",
      "Epoch 4/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 9.2569e-04 - val_loss: 5.8121e-04\n",
      "Epoch 5/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 8.1662e-04 - val_loss: 4.3147e-04\n",
      "Epoch 6/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 8.0867e-04 - val_loss: 4.1949e-04\n",
      "Epoch 7/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.5816e-04 - val_loss: 4.1317e-04\n",
      "Epoch 8/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.2812e-04 - val_loss: 4.1186e-04\n",
      "Epoch 9/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.8133e-04 - val_loss: 5.6664e-04\n",
      "Epoch 10/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 7.3564e-04 - val_loss: 3.6105e-04\n",
      "Epoch 11/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.8854e-04 - val_loss: 3.6688e-04\n",
      "Epoch 12/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.9392e-04 - val_loss: 3.6173e-04\n",
      "Epoch 13/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.5191e-04 - val_loss: 3.8870e-04\n",
      "Epoch 14/200\n",
      "548/548 [==============================] - 2s 4ms/step - loss: 6.9038e-04 - val_loss: 3.3366e-04\n",
      "Epoch 15/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.7798e-04 - val_loss: 3.5178e-04\n",
      "Epoch 16/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.8094e-04 - val_loss: 4.7331e-04\n",
      "Epoch 17/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.5085e-04 - val_loss: 4.1356e-04\n",
      "Epoch 18/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.5051e-04 - val_loss: 3.0888e-04\n",
      "Epoch 19/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.5532e-04 - val_loss: 5.6591e-04\n",
      "Epoch 20/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.3776e-04 - val_loss: 2.9082e-04\n",
      "Epoch 21/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.3153e-04 - val_loss: 4.2831e-04\n",
      "Epoch 22/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.5755e-04 - val_loss: 3.2114e-04\n",
      "Epoch 23/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.2303e-04 - val_loss: 2.8214e-04\n",
      "Epoch 24/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.2501e-04 - val_loss: 3.6017e-04\n",
      "Epoch 25/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.4156e-04 - val_loss: 4.6211e-04\n",
      "Epoch 26/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.4808e-04 - val_loss: 2.7076e-04\n",
      "Epoch 27/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.1508e-04 - val_loss: 3.0657e-04\n",
      "Epoch 28/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.0254e-04 - val_loss: 3.3614e-04\n",
      "Epoch 29/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9919e-04 - val_loss: 2.7075e-04\n",
      "Epoch 30/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.1258e-04 - val_loss: 3.5097e-04\n",
      "Epoch 31/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9439e-04 - val_loss: 2.8215e-04\n",
      "Epoch 32/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.9926e-04 - val_loss: 2.7747e-04\n",
      "Epoch 33/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.1343e-04 - val_loss: 2.7265e-04\n",
      "Epoch 34/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 5.9897e-04 - val_loss: 2.9516e-04\n",
      "Epoch 35/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8685e-04 - val_loss: 3.4341e-04\n",
      "Epoch 36/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.0202e-04 - val_loss: 3.0030e-04\n",
      "Epoch 37/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8799e-04 - val_loss: 2.6297e-04\n",
      "Epoch 38/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8648e-04 - val_loss: 2.7197e-04\n",
      "Epoch 39/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7002e-04 - val_loss: 2.6475e-04\n",
      "Epoch 40/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9323e-04 - val_loss: 4.6848e-04\n",
      "Epoch 41/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.0617e-04 - val_loss: 2.5667e-04\n",
      "Epoch 42/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.1148e-04 - val_loss: 2.9776e-04\n",
      "Epoch 43/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8645e-04 - val_loss: 2.6363e-04\n",
      "Epoch 44/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8038e-04 - val_loss: 2.5461e-04\n",
      "Epoch 45/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9769e-04 - val_loss: 2.4740e-04\n",
      "Epoch 46/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.0313e-04 - val_loss: 3.7487e-04\n",
      "Epoch 47/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6587e-04 - val_loss: 2.5207e-04\n",
      "Epoch 48/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8212e-04 - val_loss: 2.5752e-04\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7325e-04 - val_loss: 2.5804e-04\n",
      "Epoch 50/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7165e-04 - val_loss: 2.8944e-04\n",
      "Epoch 51/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8897e-04 - val_loss: 2.4815e-04\n",
      "Epoch 52/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8644e-04 - val_loss: 2.5448e-04\n",
      "Epoch 53/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8282e-04 - val_loss: 2.9471e-04\n",
      "Epoch 54/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.5345e-04 - val_loss: 2.7445e-04\n",
      "Epoch 55/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6876e-04 - val_loss: 2.5131e-04\n",
      "Epoch 56/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8203e-04 - val_loss: 2.5516e-04\n",
      "Epoch 57/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8709e-04 - val_loss: 3.4919e-04\n",
      "Epoch 58/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9732e-04 - val_loss: 3.0420e-04\n",
      "Epoch 59/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8471e-04 - val_loss: 2.8870e-04\n",
      "Epoch 60/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7752e-04 - val_loss: 2.8369e-04\n",
      "Epoch 61/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6628e-04 - val_loss: 2.8550e-04\n",
      "Epoch 62/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8687e-04 - val_loss: 2.8883e-04\n",
      "Epoch 63/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8004e-04 - val_loss: 2.4816e-04\n",
      "Epoch 64/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.5349e-04 - val_loss: 2.6332e-04\n",
      "Epoch 65/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8547e-04 - val_loss: 2.5299e-04\n",
      "Epoch 66/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7306e-04 - val_loss: 2.7180e-04\n",
      "Epoch 67/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6338e-04 - val_loss: 2.6107e-04\n",
      "Epoch 68/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.8625e-04 - val_loss: 3.1129e-04\n",
      "> Model[[24, 200, 0.2, 200, 48]] 22.068 13.467 0.956\n",
      "done\n",
      "> Model[[24, 200, 0.1, 200, 48]] 19.869 11.745 0.965\n",
      "> Model[[24, 100, 0.2, 200, 24]] 20.195 12.483 0.964\n",
      "> Model[[24, 100, 0.2, 200, 48]] 20.288 12.327 0.963\n",
      "> Model[[24, 200, 0.2, 200, 24]] 20.317 11.863 0.963\n",
      "> Model[[24, 100, 0.1, 200, 48]] 20.634 12.550 0.962\n",
      "> Model[[24, 200, 0.1, 200, 24]] 20.776 12.928 0.961\n",
      "> Model[[24, 100, 0.1, 200, 12]] 21.228 12.966 0.960\n",
      "> Model[[24, 100, 0.1, 200, 24]] 21.360 12.550 0.959\n",
      "> Model[[24, 200, 0.1, 200, 12]] 21.386 12.972 0.959\n",
      "> Model[[24, 200, 0.2, 200, 12]] 21.472 12.849 0.959\n",
      "> Model[[24, 200, 0.2, 200, 48]] 22.068 13.467 0.956\n",
      "> Model[[24, 100, 0.2, 200, 12]] 23.374 14.857 0.951\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "scores = grid_search(cfg_list)\n",
    "print('done')\n",
    "\n",
    "# list configs in ascending order of rmse\n",
    "for config, rmse, mae, R2 in scores:\n",
    "    print('> Model[%s] %.3f %.3f %.3f' % (config, rmse, mae, R2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model[[24, 200, 0.1, 200, 48]] 19.869 11.745 0.965                                                                           \n",
    "> Model[[24, 100, 0.2, 200, 24]] 20.195 12.483 0.964                                                                           \n",
    "> Model[[24, 100, 0.2, 200, 48]] 20.288 12.327 0.963                                                                           \n",
    "> Model[[24, 200, 0.2, 200, 24]] 20.317 11.863 0.963                                                                           \n",
    "> Model[[24, 100, 0.1, 200, 48]] 20.634 12.550 0.962                                                                           \n",
    "> Model[[24, 200, 0.1, 200, 24]] 20.776 12.928 0.961                                                                           \n",
    "> Model[[24, 100, 0.1, 200, 12]] 21.228 12.966 0.960                                                                           \n",
    "> Model[[24, 100, 0.1, 200, 24]] 21.360 12.550 0.959                                                                           \n",
    "> Model[[24, 200, 0.1, 200, 12]] 21.386 12.972 0.959                                                                           \n",
    "> Model[[24, 200, 0.2, 200, 12]] 21.472 12.849 0.959                                                                           \n",
    "> Model[[24, 200, 0.2, 200, 48]] 22.068 13.467 0.956                                                                           \n",
    "> Model[[24, 100, 0.2, 200, 12]] 23.374 14.857 0.951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GNCi1VIwhxBi"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "config = [24, 200, 0.1, 200, 48]\n",
    "\n",
    "# Define parameters\n",
    "n_input, n_nodes, n_drop, n_epochs, n_batch = config\n",
    "\n",
    "# Prepare training data\n",
    "train_X, train_y = to_supervised(train, n_input=24)\n",
    "val_X, val_y = to_supervised(val, n_input =24)\n",
    "\n",
    "# Define the input parameters\n",
    "tf.random.set_seed(7)\n",
    "np.random.seed(7)\n",
    "n_input, n_features = train_X.shape[1], train_X.shape[2]\n",
    "n_steps = train_X.shape[1]*train_X.shape[2]\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(n_nodes, activation='relu', input_dim = n_steps))\n",
    "model.add(Dropout(n_drop))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = 'mse' , optimizer= Adam(learning_rate = 0.001))\n",
    "\n",
    "es_callback = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-4,\n",
    "              patience=50, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOtxlRDf6SY8",
    "outputId": "a1458ece-0b01-46ac-c5bc-c77beb910b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26280, 24, 22) (26280, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJpiC2Vwx88c",
    "outputId": "d5491305-c343-4e97-8cc5-b87828efc2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 200)               105800    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 106,001\n",
      "Trainable params: 106,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "KVMs9nFJCRRq",
    "outputId": "5aa4c530-a8fb-47e7-c140-44abb6374552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=\"final_MLP.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XgCJ3XSh3jU",
    "outputId": "71134a3a-331c-419d-9e4d-bc64c04c91a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0091 - val_loss: 9.7081e-04\n",
      "Epoch 2/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 0.0012 - val_loss: 6.2358e-04\n",
      "Epoch 3/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 9.0704e-04 - val_loss: 5.2380e-04\n",
      "Epoch 4/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 8.0853e-04 - val_loss: 4.9452e-04\n",
      "Epoch 5/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 7.2284e-04 - val_loss: 4.2372e-04\n",
      "Epoch 6/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.7544e-04 - val_loss: 4.5666e-04\n",
      "Epoch 7/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.6622e-04 - val_loss: 4.0233e-04\n",
      "Epoch 8/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.2689e-04 - val_loss: 3.6026e-04\n",
      "Epoch 9/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 6.0478e-04 - val_loss: 7.0200e-04\n",
      "Epoch 10/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 6.2475e-04 - val_loss: 3.3160e-04\n",
      "Epoch 11/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.9378e-04 - val_loss: 3.3356e-04\n",
      "Epoch 12/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6747e-04 - val_loss: 3.3899e-04\n",
      "Epoch 13/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.6174e-04 - val_loss: 3.3402e-04\n",
      "Epoch 14/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.7563e-04 - val_loss: 3.2043e-04\n",
      "Epoch 15/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.5422e-04 - val_loss: 3.9888e-04\n",
      "Epoch 16/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.5191e-04 - val_loss: 3.1933e-04\n",
      "Epoch 17/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.3692e-04 - val_loss: 3.1341e-04\n",
      "Epoch 18/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.3049e-04 - val_loss: 2.9515e-04\n",
      "Epoch 19/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.0472e-04 - val_loss: 3.1212e-04\n",
      "Epoch 20/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.2318e-04 - val_loss: 2.7341e-04\n",
      "Epoch 21/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9837e-04 - val_loss: 3.0498e-04\n",
      "Epoch 22/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.1959e-04 - val_loss: 3.1261e-04\n",
      "Epoch 23/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.0593e-04 - val_loss: 2.6213e-04\n",
      "Epoch 24/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8935e-04 - val_loss: 3.4058e-04\n",
      "Epoch 25/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.1082e-04 - val_loss: 3.2663e-04\n",
      "Epoch 26/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 5.2227e-04 - val_loss: 2.6694e-04\n",
      "Epoch 27/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8581e-04 - val_loss: 3.1790e-04\n",
      "Epoch 28/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9248e-04 - val_loss: 2.8457e-04\n",
      "Epoch 29/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9669e-04 - val_loss: 2.8438e-04\n",
      "Epoch 30/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8506e-04 - val_loss: 3.3778e-04\n",
      "Epoch 31/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7569e-04 - val_loss: 2.7362e-04\n",
      "Epoch 32/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7828e-04 - val_loss: 2.5371e-04\n",
      "Epoch 33/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9577e-04 - val_loss: 2.5476e-04\n",
      "Epoch 34/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.9152e-04 - val_loss: 3.0479e-04\n",
      "Epoch 35/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8459e-04 - val_loss: 2.8734e-04\n",
      "Epoch 36/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7460e-04 - val_loss: 3.0192e-04\n",
      "Epoch 37/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6717e-04 - val_loss: 2.5896e-04\n",
      "Epoch 38/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6068e-04 - val_loss: 2.6134e-04\n",
      "Epoch 39/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6224e-04 - val_loss: 2.4159e-04\n",
      "Epoch 40/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8969e-04 - val_loss: 2.7911e-04\n",
      "Epoch 41/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.8886e-04 - val_loss: 2.5220e-04\n",
      "Epoch 42/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7976e-04 - val_loss: 3.8972e-04\n",
      "Epoch 43/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6081e-04 - val_loss: 2.7590e-04\n",
      "Epoch 44/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5834e-04 - val_loss: 2.5292e-04\n",
      "Epoch 45/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7209e-04 - val_loss: 2.5151e-04\n",
      "Epoch 46/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4242e-04 - val_loss: 2.8788e-04\n",
      "Epoch 47/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6159e-04 - val_loss: 2.5690e-04\n",
      "Epoch 48/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5393e-04 - val_loss: 2.5892e-04\n",
      "Epoch 49/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6083e-04 - val_loss: 2.4849e-04\n",
      "Epoch 50/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6198e-04 - val_loss: 2.7550e-04\n",
      "Epoch 51/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5631e-04 - val_loss: 2.4796e-04\n",
      "Epoch 52/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.7070e-04 - val_loss: 3.2202e-04\n",
      "Epoch 53/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.6555e-04 - val_loss: 2.6945e-04\n",
      "Epoch 54/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.3519e-04 - val_loss: 2.8569e-04\n",
      "Epoch 55/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4599e-04 - val_loss: 3.0931e-04\n",
      "Epoch 56/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4266e-04 - val_loss: 2.3858e-04\n",
      "Epoch 57/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5219e-04 - val_loss: 2.3526e-04\n",
      "Epoch 58/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4819e-04 - val_loss: 2.4690e-04\n",
      "Epoch 59/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5397e-04 - val_loss: 2.5403e-04\n",
      "Epoch 60/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.6114e-04 - val_loss: 2.6220e-04\n",
      "Epoch 61/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4216e-04 - val_loss: 2.4620e-04\n",
      "Epoch 62/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.5727e-04 - val_loss: 3.5802e-04\n",
      "Epoch 63/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4271e-04 - val_loss: 2.3841e-04\n",
      "Epoch 64/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 4.4202e-04 - val_loss: 2.5472e-04\n",
      "Epoch 65/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.5004e-04 - val_loss: 2.8062e-04\n",
      "Epoch 66/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 4.6241e-04 - val_loss: 2.4614e-04\n",
      "Epoch 67/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 4.5048e-04 - val_loss: 2.4002e-04\n",
      "Epoch 68/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.5612e-04 - val_loss: 2.7340e-04\n",
      "Epoch 69/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 4.4474e-04 - val_loss: 3.4780e-04\n",
      "Epoch 70/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 4.5993e-04 - val_loss: 2.5903e-04\n",
      "Epoch 71/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.6678e-04 - val_loss: 2.4331e-04\n",
      "Epoch 72/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.4995e-04 - val_loss: 2.9212e-04\n",
      "Epoch 73/200\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 4.3872e-04 - val_loss: 2.6077e-04\n",
      "Epoch 74/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.3430e-04 - val_loss: 2.5122e-04\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - 1s 3ms/step - loss: 4.3355e-04 - val_loss: 2.8557e-04\n",
      "Epoch 76/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.2955e-04 - val_loss: 2.5582e-04\n",
      "Epoch 77/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.4494e-04 - val_loss: 2.3454e-04\n",
      "Epoch 78/200\n",
      "548/548 [==============================] - 2s 3ms/step - loss: 4.4157e-04 - val_loss: 3.6606e-04\n",
      "Epoch 79/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.4605e-04 - val_loss: 2.5541e-04\n",
      "Epoch 80/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.4117e-04 - val_loss: 2.5679e-04\n",
      "Epoch 81/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.3746e-04 - val_loss: 2.3652e-04\n",
      "Epoch 82/200\n",
      "548/548 [==============================] - 1s 3ms/step - loss: 4.4427e-04 - val_loss: 2.3953e-04\n"
     ]
    }
   ],
   "source": [
    "# define inputs\n",
    "train_X = train_X.reshape((train_X.shape[0], n_steps))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_steps))\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_X, train_y, epochs=n_epochs, batch_size=n_batch, verbose=1, validation_data = (val_X,val_y),callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qAAUTp2-2n3",
    "outputId": "10b32512-2724-482e-e4a0-a5e046bd6365"
   },
   "outputs": [],
   "source": [
    "np.save(\"history_MLP48.npy\", history.history)\n",
    "model.save('MLP48.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "xPjRNB12oJTA",
    "outputId": "22a5d7a5-2520-4504-add3-c4dc411c8742"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')  # plotting train loss\n",
    "plt.plot(history.history['val_loss'], label='val')  # plotting validation loss\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJkb6lgRFq8t",
    "outputId": "84bdd6a0-c32d-418f-afef-dfc260830d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 19.869\n",
      "Test MAE: 11.745\n",
      "Test R2: 0.965\n"
     ]
    }
   ],
   "source": [
    "# shape input for model\n",
    "test_X, test_y = to_supervised(test, n_input =24)\n",
    "input_X = test_X.reshape((test_X.shape[0], test_X.shape[1]*test_X.shape[2]))\n",
    "\n",
    "# make forecast\n",
    "yhat = model.predict(input_X)\n",
    "\n",
    "# invert scaling for actual\n",
    "inv_test_y = concatenate((test_y, input_X[:, -21:]), axis=1)\n",
    "inv_test_y = scaler.inverse_transform(inv_test_y)\n",
    "inv_test_y= inv_test_y[:, 0]\n",
    "\n",
    "# invert scaling for predictions\n",
    "inv_yhat = concatenate((yhat, input_X[:, -21:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "# estimate prediction error\n",
    "rmse = sqrt(mean_squared_error(inv_test_y,inv_yhat))\n",
    "print('RMSE: %.3f' % (rmse))\n",
    "\n",
    "mae = mean_absolute_error(inv_test_y, inv_yhat)\n",
    "print('Test MAE: %.3f' % mae)\n",
    "\n",
    "R2=r2_score(inv_test_y, inv_yhat)\n",
    "print('Test R2: %.3f' % R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "CuomodozIK-g",
    "outputId": "950d409a-1b33-415a-c54c-43e12405b360"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(inv_test_y[ :250], label='actual')  # plotting actual\n",
    "plt.plot(inv_yhat[ :250], label='forecast')  # plotting forecast\n",
    "\n",
    "plt.ylabel('PM2.5')\n",
    "plt.xlabel('time in hrs')\n",
    "plt.legend(['actual', 'forecast'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "901hyntOUMdV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
